{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trainning_df = pd.read_pickle('../data/training_classif_data.pkl')\n",
    "df_with_nan = pd.read_pickle('../data/df_with_nan.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardiser les données ????\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# Standardiser toutes les colonnes du DataFrame\n",
    "\n",
    "# il faut encoder !! puis standardiser !!\n",
    "# df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9287105570705103\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFICATION 'Code_type_local'\n",
    "\n",
    "# TRAINING\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "# ########### Random forest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Random forest mieux mais 8min de calcul\n",
    "\n",
    "\n",
    "X = trainning_df.drop(columns=['Code_type_local', 'Commune', 'Section', 'No_plan', 'Nature_culture',\n",
    "            'Departement', 'Code_postal', 'day', 'month', 'year', 'latitude', 'longitude'])\n",
    "\n",
    "y = trainning_df['Code_type_local']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "\n",
    "modele_decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "modele_decision_tree.fit(X_train, y_train)\n",
    "y_pred = modele_decision_tree.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       No_disposition  Valeur_fonciere Code_postal                  Commune  \\\n",
      "1                   2          2500.00        3100                MONTLUCON   \n",
      "5                   1          2419.00        2310                   PAVANT   \n",
      "7                   1           519.00        1200         INJOUX GENISSIAT   \n",
      "8                   1         10000.00        2860  BRUYERES ET MONTBERAULT   \n",
      "10                  1        242000.00        1260            HAUT VALROMEY   \n",
      "...               ...              ...         ...                      ...   \n",
      "47182               1         78000.00        3320               LE VEURDRE   \n",
      "47183               1        160000.00        2510                   ETREUX   \n",
      "47186               1         60000.00        3320               LE VEURDRE   \n",
      "47188               1          2000.00        2270          CRECY SUR SERRE   \n",
      "47190               1         26490.75        2310                  DOMPTIN   \n",
      "\n",
      "      Section  No_plan  Nombre_de_lots  Code_type_local  Surface_reelle_bati  \\\n",
      "1          BO      458               0              NaN                  NaN   \n",
      "5           C      168               0              NaN                  NaN   \n",
      "7           C        9               0              NaN                  NaN   \n",
      "8           A      131               0              NaN                  NaN   \n",
      "10          C      232               0              NaN                  NaN   \n",
      "...       ...      ...             ...              ...                  ...   \n",
      "47182       A       54               0              NaN                  NaN   \n",
      "47183      AD      411               0              NaN                  NaN   \n",
      "47186       B     1357               0              NaN                  NaN   \n",
      "47188      AC      314               0              NaN                  NaN   \n",
      "47190      ZK       64               0              NaN                  NaN   \n",
      "\n",
      "       Nombre_pieces_principales Nature_culture  Surface_terrain day month  \\\n",
      "1                            NaN              S             75.0  14     2   \n",
      "5                            NaN             VE            122.0  23     2   \n",
      "7                            NaN              T           1730.0  11    12   \n",
      "8                            NaN             AG           2716.0  27     7   \n",
      "10                           NaN             BR           1557.0  15     6   \n",
      "...                          ...            ...              ...  ..   ...   \n",
      "47182                        NaN              J            590.0  26    11   \n",
      "47183                        NaN             PA              8.0  24     8   \n",
      "47186                        NaN              S            443.0   9     1   \n",
      "47188                        NaN              J            767.0  26     6   \n",
      "47190                        NaN             BT           2920.0  18     1   \n",
      "\n",
      "       year   latitude  longitude Departement  \n",
      "1      2018  46.338588   2.603905          03  \n",
      "5      2018  48.952892   3.283904          02  \n",
      "7      2018  46.049773   5.759914          01  \n",
      "8      2018  49.523962   3.669547          02  \n",
      "10     2018  46.031741   5.702670          01  \n",
      "...     ...        ...        ...         ...  \n",
      "47182  2018  46.742728   3.042598          03  \n",
      "47183  2018  49.999601   3.658905          02  \n",
      "47186  2018  46.742728   3.042598          03  \n",
      "47188  2018  49.698624   3.622566          02  \n",
      "47190  2018  49.015700   3.272965          02  \n",
      "\n",
      "[21912 rows x 18 columns]\n",
      "       No_disposition  Valeur_fonciere  Nombre_de_lots  Surface_reelle_bati  \\\n",
      "1                   2          2500.00               0                  NaN   \n",
      "5                   1          2419.00               0                  NaN   \n",
      "7                   1           519.00               0                  NaN   \n",
      "8                   1         10000.00               0                  NaN   \n",
      "10                  1        242000.00               0                  NaN   \n",
      "...               ...              ...             ...                  ...   \n",
      "47182               1         78000.00               0                  NaN   \n",
      "47183               1        160000.00               0                  NaN   \n",
      "47186               1         60000.00               0                  NaN   \n",
      "47188               1          2000.00               0                  NaN   \n",
      "47190               1         26490.75               0                  NaN   \n",
      "\n",
      "       Nombre_pieces_principales  Surface_terrain  \n",
      "1                            NaN             75.0  \n",
      "5                            NaN            122.0  \n",
      "7                            NaN           1730.0  \n",
      "8                            NaN           2716.0  \n",
      "10                           NaN           1557.0  \n",
      "...                          ...              ...  \n",
      "47182                        NaN            590.0  \n",
      "47183                        NaN              8.0  \n",
      "47186                        NaN            443.0  \n",
      "47188                        NaN            767.0  \n",
      "47190                        NaN           2920.0  \n",
      "\n",
      "[21912 rows x 6 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nDecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/nathan/fac/m2/s1/python/projet_prediction/src/classification.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/fac/m2/s1/python/projet_prediction/src/classification.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m y \u001b[39m=\u001b[39m individus_manquants[\u001b[39m'\u001b[39m\u001b[39mCode_type_local\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/fac/m2/s1/python/projet_prediction/src/classification.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Prédisez Code_type_local pour les individus manquants\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nathan/fac/m2/s1/python/projet_prediction/src/classification.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m predictions_code_type_local \u001b[39m=\u001b[39m modele_decision_tree\u001b[39m.\u001b[39;49mpredict(X_manquants)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/fac/m2/s1/python/projet_prediction/src/classification.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Remplacez les valeurs manquantes dans le DataFrame original avec les prédictions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/fac/m2/s1/python/projet_prediction/src/classification.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m df_with_nan\u001b[39m.\u001b[39mloc[df_with_nan[\u001b[39m'\u001b[39m\u001b[39mCode_type_local\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misna(), \u001b[39m'\u001b[39m\u001b[39mCode_type_local\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m predictions_code_type_local\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:505\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \n\u001b[1;32m    484\u001b[0m \u001b[39mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    504\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 505\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input)\n\u001b[1;32m    506\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m    507\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:471\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[0;32m--> 471\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    472\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    473\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc\n\u001b[1;32m    474\u001b[0m     ):\n\u001b[1;32m    475\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nDecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Use previous model to fill 'Code_type_local' == NaN\n",
    "\n",
    "# Réimporter les données de base, tous ceux qui ont Code_type_local == NaN, puis appliquer le modèle le classif \n",
    "\n",
    "# Sélectionnez les individus avec Code_type_local manquant\n",
    "individus_manquants = df_with_nan[df_with_nan['Code_type_local'].isna()]\n",
    "print(individus_manquants)\n",
    "\n",
    "X_manquants = individus_manquants.drop(columns=['Code_type_local', 'Commune', 'Section', 'No_plan', 'Nature_culture',\n",
    "                                                'Departement', 'Code_postal', 'day', 'month', 'year', 'latitude', 'longitude'])\n",
    "print(X_manquants)\n",
    "\n",
    "\n",
    "y = individus_manquants['Code_type_local']\n",
    "\n",
    "# Prédisez Code_type_local pour les individus manquants\n",
    "predictions_code_type_local = modele_decision_tree.predict(X_manquants)\n",
    "\n",
    "# Remplacez les valeurs manquantes dans le DataFrame original avec les prédictions\n",
    "df_with_nan.loc[df_with_nan['Code_type_local'].isna(), 'Code_type_local'] = predictions_code_type_local\n",
    "\n",
    "\n",
    "df_with_nan.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténer les 2 dataframes (sans les 'Code_type_local' manquants et avec)\n",
    "\n",
    "df = pd.concat([df_without_nan, df_with_nan])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace last empty variables\n",
    "\n",
    "median_surface_by_type = df.groupby('Code_type_local')[\n",
    "    'Surface_reelle_bati'].median()\n",
    "# Remplacez les NaN dans \"Surface_reelle_bat\" par la médiane correspondante basée sur \"Code_type_local\"\n",
    "df['Surface_reelle_bati'] = df['Surface_reelle_bati'].fillna(\n",
    "    df['Code_type_local'].map(median_surface_by_type))\n",
    "\n",
    "median_surface_by_type = df.groupby('Code_type_local')[\n",
    "    'Nombre_pieces_principales'].median()\n",
    "# Remplacez les NaN dans \"Surface_reelle_bat\" par la médiane correspondante basée sur \"Code_type_local\"\n",
    "df['Nombre_pieces_principales'] = df['Nombre_pieces_principales'].fillna(\n",
    "    df['Code_type_local'].map(median_surface_by_type))\n",
    "\n",
    "# Removing useless variables\n",
    "df = df.drop(columns=[\"Nature_culture\", \"Surface_terrain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pourcentages_nan = (df.isna().sum() / len(df)) * 100\n",
    "print(pourcentages_nan)\n",
    "print(len(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Variable 'Prix_moyen_m2'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Groupez les données par 'Commune' et calculez la somme de 'Surface_reel' et 'Valeur_fonciere' pour chaque commune\n",
    "groupe_commune = df.groupby('Commune').agg(\n",
    "    {'Surface_reelle_bati': 'sum', 'Valeur_fonciere': 'sum'})\n",
    "\n",
    "# Calculez le prix moyen au mètre carré par commune\n",
    "groupe_commune['Prix_moyen_m2'] = groupe_commune['Valeur_fonciere'] / \\\n",
    "    groupe_commune['Surface_reelle_bati']\n",
    "\n",
    "\n",
    "# Fusionnez le DataFrame original avec le DataFrame groupe_commune sur la colonne 'Commune'\n",
    "df = pd.merge(df, groupe_commune[['Prix_moyen_m2']],\n",
    "              left_on='Commune', right_index=True, how='left')\n",
    "\n",
    "\n",
    "\n",
    "# Remplace les inf par NaN\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "# Supprime les lignes avec NaN dans 'Prix_moyen_m2'\n",
    "df = df.dropna(subset=['Prix_moyen_m2'], how='any')\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final data\n",
    "\n",
    "df.to_pickle('../data/final_data.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
