{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('/Users/josephpelham/Desktop/SISE/Python/Donnees')\n",
    "#os.chdir('/home/nathan/fac/m2/s1/python/td1')\n",
    "\n",
    "\n",
    "# !! changer les chemins relatifs !!\n",
    "\n",
    "# TODO :\n",
    "\n",
    "# NB : faire un modele de régression pour chaque type de local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8175/3825783466.py:44: DtypeWarning: Columns (24,26,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_18 = pd.read_csv(chemin_fichier_2018, delimiter='|',nrows=100000)\n"
     ]
    }
   ],
   "source": [
    "## Import Data ## \n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# ! options !\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "chemin_fichier_2018 = '/home/nathan/fac/m2/s1/python/td1/valeursfoncieres-2018.txt'\n",
    "chemin_fichier_2019 = '/home/nathan/fac/m2/s1/python/td1/valeursfoncieres-2019.txt'\n",
    "chemin_fichier_2020 = '/home/nathan/fac/m2/s1/python/td1/valeursfoncieres-2020.txt'\n",
    "chemin_fichier_2021 = '/home/nathan/fac/m2/s1/python/td1/valeursfoncieres-2021.txt'\n",
    "\n",
    "chemin_fichier_2018 = '../valeursfoncieres-2018.txt'\n",
    "chemin_fichier_2019 = '../valeursfoncieres-2019.txt'\n",
    "chemin_fichier_2020 = '../valeursfoncieres-2020.txt'\n",
    "chemin_fichier_2021 = '../valeursfoncieres-2021.txt'\n",
    "\n",
    "#nombre_total_lignes = 700000\n",
    "nombre_total_lignes = 300000\n",
    "\n",
    "# Pour prendre n individus aléatoire par fichier mais très long car il faut importer tout les fichiers en entier\n",
    "indices_aleatoires_2018 = random.sample(\n",
    "    range(1, nombre_total_lignes + 1), nombre_total_lignes)\n",
    "indices_aleatoires_2019 = random.sample(\n",
    "    range(1, nombre_total_lignes + 1), nombre_total_lignes)\n",
    "indices_aleatoires_2020 = random.sample(\n",
    "    range(1, nombre_total_lignes + 1), nombre_total_lignes)\n",
    "indices_aleatoires_2021 = random.sample(\n",
    "    range(1, nombre_total_lignes + 1), nombre_total_lignes)\n",
    "\n",
    "\n",
    "#df_18 = pd.read_csv(chemin_fichier_2018, delimiter='|',skiprows=lambda x: x not in indices_aleatoires_2018)\n",
    "#df_19 = pd.read_csv(chemin_fichier_2019, delimiter='|',skiprows=lambda x: x not in indices_aleatoires_2019)\n",
    "#df_20 = pd.read_csv(chemin_fichier_2020, delimiter='|',skiprows=lambda x: x not in indices_aleatoires_2020)\n",
    "#df_21 = pd.read_csv(chemin_fichier_2021, delimiter='|',skiprows=lambda x: x not in indices_aleatoires_2021)\n",
    "\n",
    "\n",
    "#df_18 = pd.read_csv(chemin_fichier_2018, delimiter='|',nrows=nombre_total_lignes)\n",
    "#df_19 = pd.read_csv(chemin_fichier_2019, delimiter='|',nrows=nombre_total_lignes)\n",
    "#df_20 = pd.read_csv(chemin_fichier_2020, delimiter='|',nrows=nombre_total_lignes)\n",
    "#df_21 = pd.read_csv(chemin_fichier_2021, delimiter='|',nrows=nombre_total_lignes)\n",
    "\n",
    "df_18 = pd.read_csv(chemin_fichier_2018, delimiter='|',nrows=100000)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [df_18] \n",
    "\n",
    "# Remplacer les espaces par des _ dans colonnes\n",
    "for df in dataframes:\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 43 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Identifiant_de_document     0 non-null       float64\n",
      " 1   Reference_document          0 non-null       float64\n",
      " 2   1_Articles_CGI              0 non-null       float64\n",
      " 3   2_Articles_CGI              0 non-null       float64\n",
      " 4   3_Articles_CGI              0 non-null       float64\n",
      " 5   4_Articles_CGI              0 non-null       float64\n",
      " 6   5_Articles_CGI              0 non-null       float64\n",
      " 7   No_disposition              100000 non-null  int64  \n",
      " 8   Date_mutation               100000 non-null  object \n",
      " 9   Nature_mutation             100000 non-null  object \n",
      " 10  Valeur_fonciere             98532 non-null   object \n",
      " 11  No_voie                     45343 non-null   float64\n",
      " 12  B/T/Q                       3197 non-null    object \n",
      " 13  Type_de_voie                41017 non-null   object \n",
      " 14  Code_voie                   99892 non-null   object \n",
      " 15  Voie                        99892 non-null   object \n",
      " 16  Code_postal                 99891 non-null   float64\n",
      " 17  Commune                     100000 non-null  object \n",
      " 18  Code_departement            100000 non-null  int64  \n",
      " 19  Code_commune                100000 non-null  int64  \n",
      " 20  Prefixe_de_section          1976 non-null    float64\n",
      " 21  Section                     100000 non-null  object \n",
      " 22  No_plan                     100000 non-null  int64  \n",
      " 23  No_Volume                   162 non-null     float64\n",
      " 24  1er_lot                     15897 non-null   object \n",
      " 25  Surface_Carrez_du_1er_lot   4746 non-null    object \n",
      " 26  2eme_lot                    3706 non-null    object \n",
      " 27  Surface_Carrez_du_2eme_lot  1337 non-null    object \n",
      " 28  3eme_lot                    811 non-null     float64\n",
      " 29  Surface_Carrez_du_3eme_lot  208 non-null     object \n",
      " 30  4eme_lot                    273 non-null     float64\n",
      " 31  Surface_Carrez_du_4eme_lot  50 non-null      object \n",
      " 32  5eme_lot                    108 non-null     float64\n",
      " 33  Surface_Carrez_du_5eme_lot  7 non-null       object \n",
      " 34  Nombre_de_lots              100000 non-null  int64  \n",
      " 35  Code_type_local             45799 non-null   float64\n",
      " 36  Type_local                  45799 non-null   object \n",
      " 37  Identifiant_local           0 non-null       float64\n",
      " 38  Surface_reelle_bati         45690 non-null   float64\n",
      " 39  Nombre_pieces_principales   45690 non-null   float64\n",
      " 40  Nature_culture              83642 non-null   object \n",
      " 41  Nature_culture_speciale     3255 non-null    object \n",
      " 42  Surface_terrain             83642 non-null   float64\n",
      "dtypes: float64(19), int64(5), object(19)\n",
      "memory usage: 32.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframes[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifiant_de_document      100.00\n",
      "Reference_document           100.00\n",
      "1_Articles_CGI               100.00\n",
      "2_Articles_CGI               100.00\n",
      "3_Articles_CGI               100.00\n",
      "4_Articles_CGI               100.00\n",
      "5_Articles_CGI               100.00\n",
      "No_disposition                 0.00\n",
      "Date_mutation                  0.00\n",
      "Nature_mutation                0.00\n",
      "Valeur_fonciere                1.47\n",
      "No_voie                       54.66\n",
      "B/T/Q                         96.80\n",
      "Type_de_voie                  58.98\n",
      "Code_voie                      0.11\n",
      "Voie                           0.11\n",
      "Code_postal                    0.11\n",
      "Commune                        0.00\n",
      "Code_departement               0.00\n",
      "Code_commune                   0.00\n",
      "Prefixe_de_section            98.02\n",
      "Section                        0.00\n",
      "No_plan                        0.00\n",
      "No_Volume                     99.84\n",
      "1er_lot                       84.10\n",
      "Surface_Carrez_du_1er_lot     95.25\n",
      "2eme_lot                      96.29\n",
      "Surface_Carrez_du_2eme_lot    98.66\n",
      "3eme_lot                      99.19\n",
      "Surface_Carrez_du_3eme_lot    99.79\n",
      "4eme_lot                      99.73\n",
      "Surface_Carrez_du_4eme_lot    99.95\n",
      "5eme_lot                      99.89\n",
      "Surface_Carrez_du_5eme_lot    99.99\n",
      "Nombre_de_lots                 0.00\n",
      "Code_type_local               54.20\n",
      "Type_local                    54.20\n",
      "Identifiant_local            100.00\n",
      "Surface_reelle_bati           54.31\n",
      "Nombre_pieces_principales     54.31\n",
      "Nature_culture                16.36\n",
      "Nature_culture_speciale       96.75\n",
      "Surface_terrain               16.36\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pourcentages_nan = (dataframes[0].isna().sum() / len(dataframes[0])) * 100\n",
    "# Affichez les pourcentages de NaN pour chaque colonne\n",
    "print(pourcentages_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No_disposition               0.00\n",
      "Date_mutation                0.00\n",
      "Valeur_fonciere              1.22\n",
      "No_voie                     52.87\n",
      "Type_de_voie                57.61\n",
      "Code_voie                    0.01\n",
      "Voie                         0.01\n",
      "Code_postal                  0.02\n",
      "Commune                      0.00\n",
      "Code_departement             0.00\n",
      "Code_commune                 0.00\n",
      "Section                      0.00\n",
      "No_plan                      0.00\n",
      "Nombre_de_lots               0.00\n",
      "Code_type_local             53.99\n",
      "Surface_reelle_bati         54.10\n",
      "Nombre_pieces_principales   54.10\n",
      "Nature_culture              14.17\n",
      "Surface_terrain             14.17\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Remove empty columns \n",
    "columns_to_remove = [\"Identifiant_de_document\", \"Reference_document\", \"1_Articles_CGI\", \"2_Articles_CGI\", \"3_Articles_CGI\", \"4_Articles_CGI\", \"5_Articles_CGI\",\n",
    "                     \"B/T/Q\", \"Prefixe_de_section\", \"No_Volume\", \"Type_local\", \"Identifiant_local\", \"Nature_culture_speciale\",\n",
    "                     \"1er_lot\", \"Surface_Carrez_du_1er_lot\", \"2eme_lot\", \"Surface_Carrez_du_2eme_lot\", \"3eme_lot\", \"Surface_Carrez_du_3eme_lot\", \"4eme_lot\",\n",
    "                     \"Surface_Carrez_du_4eme_lot\", \"5eme_lot\", \"Surface_Carrez_du_5eme_lot\"]\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    # Créer une copie modifiée du DataFrame\n",
    "    df_modified = dataframes[i].copy()\n",
    "\n",
    "    df_modified = df_modified.drop(columns_to_remove, axis=1)\n",
    "\n",
    "    df_modified = df_modified[df_modified['Nature_mutation'] == \"Vente\"] # que les ventes\n",
    "    df_modified = df_modified.drop(columns=['Nature_mutation'])\n",
    "    \n",
    "    # sauvegarde\n",
    "    dataframes[i] = df_modified\n",
    "\n",
    "    \n",
    "\n",
    "pourcentages_nan = (dataframes[0].isna().sum() / len(dataframes[0])) * 100\n",
    "# Affichez les pourcentages de NaN pour chaque colonne\n",
    "print(pourcentages_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_disposition</th>\n",
       "      <th>Date_mutation</th>\n",
       "      <th>Valeur_fonciere</th>\n",
       "      <th>Code_postal</th>\n",
       "      <th>Commune</th>\n",
       "      <th>Section</th>\n",
       "      <th>No_plan</th>\n",
       "      <th>Nombre_de_lots</th>\n",
       "      <th>Code_type_local</th>\n",
       "      <th>Surface_reelle_bati</th>\n",
       "      <th>Nombre_pieces_principales</th>\n",
       "      <th>Nature_culture</th>\n",
       "      <th>Surface_terrain</th>\n",
       "      <th>adresse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>03/01/2018</td>\n",
       "      <td>109000,00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>BOURG-EN-BRESSE</td>\n",
       "      <td>AN</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13 RUE 1660 GEN LOGEROT 1000.0 BOURG-EN-BRESSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>03/01/2018</td>\n",
       "      <td>109000,00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>BOURG-EN-BRESSE</td>\n",
       "      <td>AN</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13 RUE 1660 GEN LOGEROT 1000.0 BOURG-EN-BRESSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>04/01/2018</td>\n",
       "      <td>239300,00</td>\n",
       "      <td>1250.00</td>\n",
       "      <td>NIVIGNE ET SURAN</td>\n",
       "      <td>AH</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>S</td>\n",
       "      <td>949.00</td>\n",
       "      <td>4 RUE 0025 DE LA BARMETTE 1250.0 NIVIGNE ET SURAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>04/01/2018</td>\n",
       "      <td>239300,00</td>\n",
       "      <td>1250.00</td>\n",
       "      <td>NIVIGNE ET SURAN</td>\n",
       "      <td>AH</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>AG</td>\n",
       "      <td>420.00</td>\n",
       "      <td>4 RUE 0025 DE LA BARMETTE 1250.0 NIVIGNE ET SURAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>04/01/2018</td>\n",
       "      <td>239300,00</td>\n",
       "      <td>1250.00</td>\n",
       "      <td>NIVIGNE ET SURAN</td>\n",
       "      <td>AH</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>AG</td>\n",
       "      <td>420.00</td>\n",
       "      <td>4 RUE 0025 DE LA BARMETTE 1250.0 NIVIGNE ET SURAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No_disposition Date_mutation Valeur_fonciere  Code_postal  \\\n",
       "0               1    03/01/2018       109000,00      1000.00   \n",
       "1               1    03/01/2018       109000,00      1000.00   \n",
       "2               1    04/01/2018       239300,00      1250.00   \n",
       "3               1    04/01/2018       239300,00      1250.00   \n",
       "4               1    04/01/2018       239300,00      1250.00   \n",
       "\n",
       "            Commune Section  No_plan  Nombre_de_lots  Code_type_local  \\\n",
       "0   BOURG-EN-BRESSE      AN       73               2             2.00   \n",
       "1   BOURG-EN-BRESSE      AN       73               1             3.00   \n",
       "2  NIVIGNE ET SURAN      AH      186               0             1.00   \n",
       "3  NIVIGNE ET SURAN      AH      186               0             1.00   \n",
       "4  NIVIGNE ET SURAN      AH      186               0             1.00   \n",
       "\n",
       "   Surface_reelle_bati  Nombre_pieces_principales Nature_culture  \\\n",
       "0                73.00                       4.00            NaN   \n",
       "1                 0.00                       0.00            NaN   \n",
       "2               163.00                       4.00              S   \n",
       "3               163.00                       4.00             AG   \n",
       "4                51.00                       2.00             AG   \n",
       "\n",
       "   Surface_terrain                                            adresse  \n",
       "0              NaN     13 RUE 1660 GEN LOGEROT 1000.0 BOURG-EN-BRESSE  \n",
       "1              NaN     13 RUE 1660 GEN LOGEROT 1000.0 BOURG-EN-BRESSE  \n",
       "2           949.00  4 RUE 0025 DE LA BARMETTE 1250.0 NIVIGNE ET SURAN  \n",
       "3           420.00  4 RUE 0025 DE LA BARMETTE 1250.0 NIVIGNE ET SURAN  \n",
       "4           420.00  4 RUE 0025 DE LA BARMETTE 1250.0 NIVIGNE ET SURAN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create variable 'adresse' \n",
    "\n",
    "columns_for_adress = [\"No_voie\", \"Type_de_voie\", \"Code_voie\",\n",
    "                      \"Voie\", \"Code_commune\", \"Code_departement\"]\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    # Créer une copie modifiée du DataFrame\n",
    "    df_modified = dataframes[i].copy()\n",
    "\n",
    "    df_modified['Code_postal'] = df_modified.groupby('Commune')['Code_postal'].transform(lambda x: x.fillna(\n",
    "        method='ffill').fillna(method='bfill'))  # match les code postal vide avec les communes (bien)\n",
    "    \n",
    "    df_modified['No_voie'] = df_modified['No_voie'].apply(lambda x: str(int(x)) if pd.notnull(\n",
    "        x) else '').astype(str)  # change le type si non il y a une valeur sinon affiche rien\n",
    "\n",
    "    df_modified['adresse'] = df_modified['No_voie'] + ' ' + df_modified['Type_de_voie'].astype(str) + ' ' + \\\n",
    "        df_modified['Code_voie'].astype(str) + ' ' + df_modified['Voie'].astype(str) + ' ' + \\\n",
    "        df_modified['Code_postal'].astype(str) + ' ' + df_modified['Commune']\n",
    "    \n",
    "    \n",
    "    # Après la création de l'adresse on remove les variables concatenées et les autres inutiles\n",
    "    df_modified = df_modified.drop(columns_for_adress, axis=1)\n",
    "\n",
    "    # sauvegarde\n",
    "    dataframes[i] = df_modified\n",
    "\n",
    "dataframes[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_disposition</th>\n",
       "      <th>Date_mutation</th>\n",
       "      <th>Valeur_fonciere</th>\n",
       "      <th>Code_postal</th>\n",
       "      <th>Commune</th>\n",
       "      <th>Section</th>\n",
       "      <th>No_plan</th>\n",
       "      <th>Nombre_de_lots</th>\n",
       "      <th>Code_type_local</th>\n",
       "      <th>Surface_reelle_bati</th>\n",
       "      <th>Nombre_pieces_principales</th>\n",
       "      <th>Nature_culture</th>\n",
       "      <th>Surface_terrain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>03/01/2018</td>\n",
       "      <td>109000,00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>BOURG-EN-BRESSE</td>\n",
       "      <td>AN</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>04/01/2018</td>\n",
       "      <td>239300,00</td>\n",
       "      <td>1250.00</td>\n",
       "      <td>NIVIGNE ET SURAN</td>\n",
       "      <td>AH</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>S</td>\n",
       "      <td>949.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>04/01/2018</td>\n",
       "      <td>90000,00</td>\n",
       "      <td>1380.00</td>\n",
       "      <td>SAINT-CYR-SUR-MENTHON</td>\n",
       "      <td>ZR</td>\n",
       "      <td>359</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>278.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>04/01/2018</td>\n",
       "      <td>90000,00</td>\n",
       "      <td>1380.00</td>\n",
       "      <td>SAINT-CYR-SUR-MENTHON</td>\n",
       "      <td>ZR</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>S</td>\n",
       "      <td>347.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>10/01/2018</td>\n",
       "      <td>3150,00</td>\n",
       "      <td>1160.00</td>\n",
       "      <td>PONT-D AIN</td>\n",
       "      <td>AM</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>126.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No_disposition Date_mutation Valeur_fonciere  Code_postal  \\\n",
       "0               1    03/01/2018       109000,00      1000.00   \n",
       "2               1    04/01/2018       239300,00      1250.00   \n",
       "6               1    04/01/2018        90000,00      1380.00   \n",
       "7               1    04/01/2018        90000,00      1380.00   \n",
       "9               2    10/01/2018         3150,00      1160.00   \n",
       "\n",
       "                 Commune Section  No_plan  Nombre_de_lots  Code_type_local  \\\n",
       "0        BOURG-EN-BRESSE      AN       73               2             2.00   \n",
       "2       NIVIGNE ET SURAN      AH      186               0             1.00   \n",
       "6  SAINT-CYR-SUR-MENTHON      ZR      359               0              NaN   \n",
       "7  SAINT-CYR-SUR-MENTHON      ZR      361               0             1.00   \n",
       "9             PONT-D AIN      AM      461               0              NaN   \n",
       "\n",
       "   Surface_reelle_bati  Nombre_pieces_principales Nature_culture  \\\n",
       "0                73.00                       4.00            NaN   \n",
       "2               163.00                       4.00              S   \n",
       "6                  NaN                        NaN              S   \n",
       "7               150.00                       3.00              S   \n",
       "9                  NaN                        NaN              S   \n",
       "\n",
       "   Surface_terrain  \n",
       "0              NaN  \n",
       "2           949.00  \n",
       "6           278.00  \n",
       "7           347.00  \n",
       "9           126.00  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates (date_mutation et adresse)\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    # Créer une copie modifiée du DataFrame\n",
    "    df_modified = dataframes[i].copy()\n",
    "\n",
    "    # Remove duplicates (date_mutation et adresse)\n",
    "    df_modified = df_modified.drop_duplicates(\n",
    "        subset=[\"Date_mutation\", \"adresse\"])\n",
    "\n",
    "    # 'adresse' useless maintenant => remove\n",
    "    df_modified = df_modified.drop(\"adresse\", axis=1)\n",
    "\n",
    "    # sauvegarde\n",
    "    dataframes[i] = df_modified\n",
    "\n",
    "dataframes[0].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00    16146\n",
      "2.00     5215\n",
      "3.00     3431\n",
      "4.00     1784\n",
      "Name: Code_type_local, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Affichez le nombre d'individus par modalité de la colonne 'Code_type_local'\n",
    "\n",
    "comptage_modalites = dataframes[0]['Code_type_local'].value_counts()\n",
    "print(comptage_modalites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before :  50169\n",
      "after :  50169 \n",
      "\n",
      "1.00    16146\n",
      "2.00     5215\n",
      "3.00     3431\n",
      "4.00     1784\n",
      "Name: Code_type_local, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"before : \", len(dataframes[0]))\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    # Créer une copie modifiée du DataFrame\n",
    "    df_modified = dataframes[i].copy()\n",
    "\n",
    "    #df_modified = df_modified.dropna() # on ne fait plus ça\n",
    "\n",
    "    df_modified['Valeur_fonciere'] = df_modified['Valeur_fonciere'].astype(str).str.replace(',', '.').astype(float)  \n",
    "\n",
    "    dataframes[i] = df_modified\n",
    "\n",
    "    \n",
    "print(\"after : \", len(dataframes[0]), \"\\n\")\n",
    "\n",
    "comptage_modalites = dataframes[0]['Code_type_local'].value_counts()\n",
    "print(comptage_modalites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No_disposition                   0\n",
      "Date_mutation                    0\n",
      "Valeur_fonciere                433\n",
      "Code_postal                      0\n",
      "Commune                          0\n",
      "Section                          0\n",
      "No_plan                          0\n",
      "Nombre_de_lots                   0\n",
      "Code_type_local              23593\n",
      "Surface_reelle_bati          23665\n",
      "Nombre_pieces_principales    23665\n",
      "Nature_culture                8021\n",
      "Surface_terrain               8021\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "masque_nan = dataframes[0].isna()\n",
    "\n",
    "# Utilisez sum() pour compter le nombre de valeurs manquantes (True) dans chaque colonne\n",
    "nombre_nan_par_colonne = masque_nan.sum()\n",
    "print(nombre_nan_par_colonne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before :  50169\n",
      "-12554.599999999999\n",
      "429741.4 \n",
      "\n",
      "after :  47164 \n",
      "\n",
      "1.00    15227\n",
      "2.00     4991\n",
      "3.00     3288\n",
      "4.00     1515\n",
      "Name: Code_type_local, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove individus with at least one NaN and individus à 1e symbolique\n",
    "\n",
    "print(\"before : \", len(dataframes[0]))\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    df_modified = dataframes[i].copy()\n",
    "   \n",
    "\n",
    "    # OUTLIERS \n",
    "    df_modified = df_modified.dropna(subset=['Valeur_fonciere'])\n",
    "    Q1 = df_modified['Valeur_fonciere'].quantile(0.25)\n",
    "    Q3 = df_modified['Valeur_fonciere'].quantile(0.75)\n",
    "    \n",
    "    #print(Q1)\n",
    "    #print(Q3)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Définissez les limites supérieure et inférieure pour détecter les outliers\n",
    "    limite_inferieure = Q1 - 0.3 * IQR\n",
    "    limite_superieure = Q3 + 1.7 * IQR\n",
    "\n",
    "    print(limite_inferieure)\n",
    "    print(limite_superieure,\"\\n\")\n",
    "    \n",
    "    df_sans_outliers = df_modified[(df_modified['Valeur_fonciere'] >= limite_inferieure) & (df_modified['Valeur_fonciere'] <= limite_superieure)]\n",
    "\n",
    "    # sauvegarde\n",
    "    dataframes[i] = df_sans_outliers\n",
    "\n",
    "\n",
    "print(\"after : \", len(dataframes[0]), \"\\n\")\n",
    "\n",
    "comptage_modalites = dataframes[0]['Code_type_local'].value_counts()\n",
    "print(comptage_modalites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_disposition</th>\n",
       "      <th>Valeur_fonciere</th>\n",
       "      <th>Code_postal</th>\n",
       "      <th>Commune</th>\n",
       "      <th>Section</th>\n",
       "      <th>No_plan</th>\n",
       "      <th>Nombre_de_lots</th>\n",
       "      <th>Code_type_local</th>\n",
       "      <th>Surface_reelle_bati</th>\n",
       "      <th>Nombre_pieces_principales</th>\n",
       "      <th>Nature_culture</th>\n",
       "      <th>Surface_terrain</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>109000.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>BOURG-EN-BRESSE</td>\n",
       "      <td>AN</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>239300.00</td>\n",
       "      <td>1250.00</td>\n",
       "      <td>NIVIGNE ET SURAN</td>\n",
       "      <td>AH</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>S</td>\n",
       "      <td>949.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>90000.00</td>\n",
       "      <td>1380.00</td>\n",
       "      <td>SAINT-CYR-SUR-MENTHON</td>\n",
       "      <td>ZR</td>\n",
       "      <td>359</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>278.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>90000.00</td>\n",
       "      <td>1380.00</td>\n",
       "      <td>SAINT-CYR-SUR-MENTHON</td>\n",
       "      <td>ZR</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>S</td>\n",
       "      <td>347.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3150.00</td>\n",
       "      <td>1160.00</td>\n",
       "      <td>PONT-D AIN</td>\n",
       "      <td>AM</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>126.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No_disposition  Valeur_fonciere  Code_postal                Commune  \\\n",
       "0               1        109000.00      1000.00        BOURG-EN-BRESSE   \n",
       "2               1        239300.00      1250.00       NIVIGNE ET SURAN   \n",
       "6               1         90000.00      1380.00  SAINT-CYR-SUR-MENTHON   \n",
       "7               1         90000.00      1380.00  SAINT-CYR-SUR-MENTHON   \n",
       "9               2          3150.00      1160.00             PONT-D AIN   \n",
       "\n",
       "  Section  No_plan  Nombre_de_lots  Code_type_local  Surface_reelle_bati  \\\n",
       "0      AN       73               2             2.00                73.00   \n",
       "2      AH      186               0             1.00               163.00   \n",
       "6      ZR      359               0              NaN                  NaN   \n",
       "7      ZR      361               0             1.00               150.00   \n",
       "9      AM      461               0              NaN                  NaN   \n",
       "\n",
       "   Nombre_pieces_principales Nature_culture  Surface_terrain day month  year  \n",
       "0                       4.00            NaN              NaN   3     1  2018  \n",
       "2                       4.00              S           949.00   4     1  2018  \n",
       "6                        NaN              S           278.00   4     1  2018  \n",
       "7                       3.00              S           347.00   4     1  2018  \n",
       "9                        NaN              S           126.00  10     1  2018  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Créer la variable \"month\" & \"year\" \n",
    "\n",
    "# NB : Utile si on la mets en 'int' et pas en objet, car le prix de l'immobilier augmente chaque année, donc plus l'année augmente plus le prix aussi\n",
    "# alors qu'en 'objet' inutile car dans ce sont les data de 2022 qui vont être testés (à revoir quand même)\n",
    "\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    # Créer une copie modifiée du DataFrame\n",
    "    df_modified = dataframes[i].copy()\n",
    "\n",
    "    df_modified['Date_mutation'] = pd.to_datetime(df_modified['Date_mutation'], format='%d/%m/%Y')\n",
    "\n",
    "    # Extract the year component and create a new 'year' column\n",
    "    df_modified['day'] = df_modified['Date_mutation'].dt.day\n",
    "    df_modified['day'] = df_modified['day'].astype(object)\n",
    "\n",
    "    df_modified['month'] = df_modified['Date_mutation'].dt.month\n",
    "    df_modified['month'] = df_modified['month'].astype(object)\n",
    "\n",
    "    df_modified['year'] = df_modified['Date_mutation'].dt.year\n",
    "    df_modified['year'] = df_modified['year'].astype(object)\n",
    "\n",
    "    df_modified = df_modified.drop(\"Date_mutation\",axis=1)\n",
    "    \n",
    "    # sauvegarde\n",
    "    dataframes[i] = df_modified\n",
    "\n",
    "dataframes[0].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47164 entries, 0 to 99999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   No_disposition             47164 non-null  int64  \n",
      " 1   Valeur_fonciere            47164 non-null  float64\n",
      " 2   Code_postal                47164 non-null  object \n",
      " 3   Commune                    47164 non-null  object \n",
      " 4   Section                    47164 non-null  object \n",
      " 5   No_plan                    47164 non-null  int64  \n",
      " 6   Nombre_de_lots             47164 non-null  int64  \n",
      " 7   Code_type_local            25021 non-null  float64\n",
      " 8   Surface_reelle_bati        24978 non-null  float64\n",
      " 9   Nombre_pieces_principales  24978 non-null  float64\n",
      " 10  Nature_culture             39434 non-null  object \n",
      " 11  Surface_terrain            39434 non-null  float64\n",
      " 12  day                        47164 non-null  object \n",
      " 13  month                      47164 non-null  object \n",
      " 14  year                       47164 non-null  object \n",
      "dtypes: float64(5), int64(3), object(7)\n",
      "memory usage: 5.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_disposition</th>\n",
       "      <th>Valeur_fonciere</th>\n",
       "      <th>Code_postal</th>\n",
       "      <th>Commune</th>\n",
       "      <th>Section</th>\n",
       "      <th>No_plan</th>\n",
       "      <th>Nombre_de_lots</th>\n",
       "      <th>Code_type_local</th>\n",
       "      <th>Surface_reelle_bati</th>\n",
       "      <th>Nombre_pieces_principales</th>\n",
       "      <th>Nature_culture</th>\n",
       "      <th>Surface_terrain</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>109000.00</td>\n",
       "      <td>1000</td>\n",
       "      <td>BOURG-EN-BRESSE</td>\n",
       "      <td>AN</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>239300.00</td>\n",
       "      <td>1250</td>\n",
       "      <td>NIVIGNE ET SURAN</td>\n",
       "      <td>AH</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>S</td>\n",
       "      <td>949.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>90000.00</td>\n",
       "      <td>1380</td>\n",
       "      <td>SAINT-CYR-SUR-MENTHON</td>\n",
       "      <td>ZR</td>\n",
       "      <td>359</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>278.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>90000.00</td>\n",
       "      <td>1380</td>\n",
       "      <td>SAINT-CYR-SUR-MENTHON</td>\n",
       "      <td>ZR</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>S</td>\n",
       "      <td>347.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3150.00</td>\n",
       "      <td>1160</td>\n",
       "      <td>PONT-D AIN</td>\n",
       "      <td>AM</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>126.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No_disposition  Valeur_fonciere Code_postal                Commune Section  \\\n",
       "0               1        109000.00        1000        BOURG-EN-BRESSE      AN   \n",
       "2               1        239300.00        1250       NIVIGNE ET SURAN      AH   \n",
       "6               1         90000.00        1380  SAINT-CYR-SUR-MENTHON      ZR   \n",
       "7               1         90000.00        1380  SAINT-CYR-SUR-MENTHON      ZR   \n",
       "9               2          3150.00        1160             PONT-D AIN      AM   \n",
       "\n",
       "   No_plan  Nombre_de_lots  Code_type_local  Surface_reelle_bati  \\\n",
       "0       73               2             2.00                73.00   \n",
       "2      186               0             1.00               163.00   \n",
       "6      359               0              NaN                  NaN   \n",
       "7      361               0             1.00               150.00   \n",
       "9      461               0              NaN                  NaN   \n",
       "\n",
       "   Nombre_pieces_principales Nature_culture  Surface_terrain day month  year  \n",
       "0                       4.00            NaN              NaN   3     1  2018  \n",
       "2                       4.00              S           949.00   4     1  2018  \n",
       "6                        NaN              S           278.00   4     1  2018  \n",
       "7                       3.00              S           347.00   4     1  2018  \n",
       "9                        NaN              S           126.00  10     1  2018  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change data types\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    # Créer une copie modifiée du DataFrame\n",
    "    df_modified = dataframes[i].copy()\n",
    "\n",
    "    df_modified = df_modified.dropna(subset=['Code_postal'])\n",
    "    df_modified['Code_postal'] = df_modified['Code_postal'].astype(int)\n",
    "    df_modified['Code_postal'] = df_modified['Code_postal'].astype(object) # puis en objet\n",
    "\n",
    "\n",
    "    # sauvegarde\n",
    "    dataframes[i] = df_modified\n",
    "\n",
    "\n",
    "print(dataframes[0].info())\n",
    "dataframes[0].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_commune_INSEE</th>\n",
       "      <th>nom_commune_postal</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>libelle_acheminement</th>\n",
       "      <th>ligne_5</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>code_commune</th>\n",
       "      <th>article</th>\n",
       "      <th>nom_commune</th>\n",
       "      <th>nom_commune_complet</th>\n",
       "      <th>code_departement</th>\n",
       "      <th>nom_departement</th>\n",
       "      <th>code_region</th>\n",
       "      <th>nom_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>L ABERGEMENT CLEMENCIAT</td>\n",
       "      <td>1400</td>\n",
       "      <td>L ABERGEMENT CLEMENCIAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.15</td>\n",
       "      <td>4.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>L'</td>\n",
       "      <td>Abergement-Clémenciat</td>\n",
       "      <td>L'Abergement-Clémenciat</td>\n",
       "      <td>1</td>\n",
       "      <td>Ain</td>\n",
       "      <td>84.00</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>L ABERGEMENT DE VAREY</td>\n",
       "      <td>1640</td>\n",
       "      <td>L ABERGEMENT DE VAREY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.01</td>\n",
       "      <td>5.43</td>\n",
       "      <td>2.00</td>\n",
       "      <td>L'</td>\n",
       "      <td>Abergement-de-Varey</td>\n",
       "      <td>L'Abergement-de-Varey</td>\n",
       "      <td>1</td>\n",
       "      <td>Ain</td>\n",
       "      <td>84.00</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004</td>\n",
       "      <td>AMBERIEU EN BUGEY</td>\n",
       "      <td>1500</td>\n",
       "      <td>AMBERIEU EN BUGEY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.96</td>\n",
       "      <td>5.37</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ambérieu-en-Bugey</td>\n",
       "      <td>Ambérieu-en-Bugey</td>\n",
       "      <td>1</td>\n",
       "      <td>Ain</td>\n",
       "      <td>84.00</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005</td>\n",
       "      <td>AMBERIEUX EN DOMBES</td>\n",
       "      <td>1330</td>\n",
       "      <td>AMBERIEUX EN DOMBES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.00</td>\n",
       "      <td>4.91</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ambérieux-en-Dombes</td>\n",
       "      <td>Ambérieux-en-Dombes</td>\n",
       "      <td>1</td>\n",
       "      <td>Ain</td>\n",
       "      <td>84.00</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1006</td>\n",
       "      <td>AMBLEON</td>\n",
       "      <td>1300</td>\n",
       "      <td>AMBLEON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.75</td>\n",
       "      <td>5.59</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ambléon</td>\n",
       "      <td>Ambléon</td>\n",
       "      <td>1</td>\n",
       "      <td>Ain</td>\n",
       "      <td>84.00</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code_commune_INSEE       nom_commune_postal  code_postal  \\\n",
       "0               1001  L ABERGEMENT CLEMENCIAT         1400   \n",
       "1               1002    L ABERGEMENT DE VAREY         1640   \n",
       "2               1004        AMBERIEU EN BUGEY         1500   \n",
       "3               1005      AMBERIEUX EN DOMBES         1330   \n",
       "4               1006                  AMBLEON         1300   \n",
       "\n",
       "      libelle_acheminement ligne_5  latitude  longitude  code_commune article  \\\n",
       "0  L ABERGEMENT CLEMENCIAT     NaN     46.15       4.93          1.00      L'   \n",
       "1    L ABERGEMENT DE VAREY     NaN     46.01       5.43          2.00      L'   \n",
       "2        AMBERIEU EN BUGEY     NaN     45.96       5.37          4.00     NaN   \n",
       "3      AMBERIEUX EN DOMBES     NaN     46.00       4.91          5.00     NaN   \n",
       "4                  AMBLEON     NaN     45.75       5.59          6.00     NaN   \n",
       "\n",
       "             nom_commune      nom_commune_complet code_departement  \\\n",
       "0  Abergement-Clémenciat  L'Abergement-Clémenciat                1   \n",
       "1    Abergement-de-Varey    L'Abergement-de-Varey                1   \n",
       "2      Ambérieu-en-Bugey        Ambérieu-en-Bugey                1   \n",
       "3    Ambérieux-en-Dombes      Ambérieux-en-Dombes                1   \n",
       "4                Ambléon                  Ambléon                1   \n",
       "\n",
       "  nom_departement  code_region            nom_region  \n",
       "0             Ain        84.00  Auvergne-Rhône-Alpes  \n",
       "1             Ain        84.00  Auvergne-Rhône-Alpes  \n",
       "2             Ain        84.00  Auvergne-Rhône-Alpes  \n",
       "3             Ain        84.00  Auvergne-Rhône-Alpes  \n",
       "4             Ain        84.00  Auvergne-Rhône-Alpes  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load longitude, latitude, 'Code_postal' dataframe\n",
    "\n",
    "geo = pd.read_csv('../data/communes-departement-region.csv')\n",
    "\n",
    "geo.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550  individus avec un nom de commune pas trouvé, on les enlève du dataset\n",
      "nombre final d'individus :  46614\n"
     ]
    }
   ],
   "source": [
    "\n",
    "geo.rename(columns={'code_postal': 'Code_postal'}, inplace=True)\n",
    "geo.rename(columns={'nom_commune_postal': 'Commune'}, inplace=True)\n",
    "geo.rename(columns={'code_departement': 'Code_departement'}, inplace=True)\n",
    "\n",
    "doublons = geo[geo.duplicated(subset=['Code_postal', 'Commune'], keep=False)] # voir les doublons\n",
    "\n",
    "geo = geo.drop_duplicates(subset=['Code_postal', 'Commune']) # OK -> supprmime les doublons Code postal => Commune, car quelques fois il y a une 'petite' commune dedans la grande enfin bref\n",
    "geo['Commune'] = geo['Commune'].str.replace('-', ' ') \n",
    "geo['Commune'] = geo['Commune'].str.replace('ST', 'SAINT')  # format 'ST' et 'SAINT'\n",
    "geo['Commune'] = geo['Commune'].str.replace('\\'', ' ')\n",
    "\n",
    "geo_commune = geo[['Commune', 'Code_postal', 'latitude', 'longitude']]\n",
    "\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    # Créer une copie modifiée du DataFrame\n",
    "    df_modified = dataframes[i].copy()\n",
    "\n",
    "    # Changement de format pour le merge, pour uniformiser tout et garder le maximum d information\n",
    "    \n",
    "    df_modified['Commune'] = df_modified['Commune'].str.replace('-', ' ')\n",
    "\n",
    "    \n",
    "    df_modified['Commune'] = df_modified['Commune'].str.replace('ST', 'SAINT')\n",
    "\n",
    "    \n",
    "    df_modified['Commune'] = df_modified['Commune'].str.replace('\\'', ' ')\n",
    "\n",
    "\n",
    "    # MERGE\n",
    "    \n",
    "    df_modified = pd.merge(df_modified, geo_commune, on=[\n",
    "        'Commune', 'Code_postal'], how='left')  # OK -> merge la commune et le code postal, car desfois la commune est dans différent département \n",
    "\n",
    "\n",
    "    # Le reste des communes non trouvé c'est des erreurs dans le fichier geo, exemple => LA SALLE DES ALPES, dans les data => \"LA SALLE\", IMPOSSIBLE À gérer ce genre d'erreur humaine => à enlever\n",
    "    print(df_modified['longitude'].isna().sum(),\" individus avec un nom de commune pas trouvé, on les enlève du dataset\")\n",
    "    df_modified = df_modified.dropna(subset=['longitude'])\n",
    "\n",
    "    print(\"nombre final d'individus : \",len(df_modified))\n",
    "\n",
    "    #df.head(20)\n",
    "    # sauvegarde\n",
    "    dataframes[i] = df_modified\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_department(code_postal):\n",
    "    if 20000 <= code_postal <= 20190:\n",
    "        return '2A' # Pour gérer la corse sud\n",
    "    elif 20200 <= code_postal <= 20270:\n",
    "        return '2B' # Pour gérer la corse nord\n",
    "    elif len(str(code_postal)) == 4:\n",
    "        dep = '0' + str(code_postal)[:1] # Pour gérer les 10 premiers département\n",
    "        return dep\n",
    "    else:\n",
    "        dep = str(code_postal)[:2]\n",
    "        return dep \n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    # Créer une copie modifiée du DataFrame\n",
    "    df_modified = dataframes[i].copy()\n",
    "    # Appliquez la fonction à la colonne 'Code_postal' en utilisant apply()\n",
    "    df_modified['Departement'] = df_modified['Code_postal'].apply(lambda x: assign_department(x))\n",
    "    df_modified['Departement'] = df_modified['Departement'].astype(str)\n",
    "\n",
    "    dataframes[i] = df_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample random % of each year\n",
    "df_18_nan = dataframes[0].sample(frac=1, random_state=42)\n",
    "\n",
    "\n",
    "df_sauvegarde_with_nan = pd.concat([df_18_nan], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    # Créer une copie modifiée du DataFrame\n",
    "    df_modified = dataframes[i].copy()\n",
    "    \n",
    "    # Créer une copie modifiée du DataFrame\n",
    "    df_modified = df_modified.dropna() # test\n",
    "    \n",
    "    df_modified['Code_type_local'] = df_modified['Code_type_local'].astype(int)  \n",
    "\n",
    "    dataframes[i] = df_modified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample random % of each year\n",
    "df_18_s = dataframes[0].sample(frac=1, random_state=42)\n",
    "\n",
    "\n",
    "# Combine sampled subsets\n",
    "df = pd.concat([df_18_s], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise les données \n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "# Standardiser toutes les colonnes du DataFrame\n",
    "\n",
    "# il faut encoder !! puis standardiser !!\n",
    "#df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "#df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9305852615205134\n"
     ]
    }
   ],
   "source": [
    "# CLASSIF de Code_type_local\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "# ########### Random forest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Random forest mieux mais 8min de calcul\n",
    "\n",
    "\n",
    "X = df.drop(columns=['Code_type_local','Commune','Section','No_plan','Nature_culture','Departement','Code_postal','day','month','year','latitude','longitude'])\n",
    "\n",
    "y = df['Code_type_local'] # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "    \n",
    "modele_decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "modele_decision_tree.fit(X_train, y_train)\n",
    "y_pred = modele_decision_tree.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       No_disposition  Valeur_fonciere Code_postal  \\\n",
      "4157                1        295800.00        1960   \n",
      "43059               1          3000.00        4320   \n",
      "24047               1        257343.00        2290   \n",
      "17303               1        100000.00        2340   \n",
      "11330               1          5000.00        1200   \n",
      "...               ...              ...         ...   \n",
      "37600               2         13950.00        3430   \n",
      "17156               1         92000.00        2700   \n",
      "11516               1         12095.00        1100   \n",
      "38576               1           100.00        3500   \n",
      "16087               1        235000.00        1700   \n",
      "\n",
      "                           Commune Section  No_plan  Nombre_de_lots  \\\n",
      "4157                      PERONNAS      AL       25               0   \n",
      "43059                      SAUSSES       A      411               0   \n",
      "24047                      AMBLENY      ZC      113               0   \n",
      "17303          CLERMONT LES FERMES      ZD       29               0   \n",
      "11330                       VILLES       A      175               0   \n",
      "...                            ...     ...      ...             ...   \n",
      "37600                    TORTEZAIS      ZC        1               0   \n",
      "17156                     TERGNIER      AH      398               0   \n",
      "11516                    MARTIGNAT       C      994               0   \n",
      "38576      VERNEUIL EN BOURBONNAIS      ZB       48               0   \n",
      "16087  SAINT MAURICE DE BEYNOSAINT      AH      310               0   \n",
      "\n",
      "       Code_type_local  Surface_reelle_bati  Nombre_pieces_principales  \\\n",
      "4157               NaN                  NaN                        NaN   \n",
      "43059              NaN                  NaN                        NaN   \n",
      "24047              NaN                  NaN                        NaN   \n",
      "17303              NaN                  NaN                        NaN   \n",
      "11330              NaN                  NaN                        NaN   \n",
      "...                ...                  ...                        ...   \n",
      "37600              NaN                  NaN                        NaN   \n",
      "17156              NaN                  NaN                        NaN   \n",
      "11516              NaN                  NaN                        NaN   \n",
      "38576              NaN                  NaN                        NaN   \n",
      "16087              NaN                  NaN                        NaN   \n",
      "\n",
      "      Nature_culture  Surface_terrain day month  year  latitude  longitude  \\\n",
      "4157               S           919.00  16    11  2018     46.17       5.22   \n",
      "43059             BT          2610.00  28     8  2018     44.01       6.78   \n",
      "24047              T           743.00   2     3  2018     49.38       3.18   \n",
      "17303              J           508.00  14     3  2018     49.66       3.94   \n",
      "11330             BS          4900.00   4    12  2018     46.10       5.76   \n",
      "...              ...              ...  ..   ...   ...       ...        ...   \n",
      "37600              T         12183.00  24     9  2018     46.45       2.87   \n",
      "17156              S           136.00  17     2  2018     49.66       3.30   \n",
      "11516              P            30.00   4    12  2018     46.20       5.61   \n",
      "38576             CA           620.00   1     3  2018     46.35       3.25   \n",
      "16087              S          1123.00  22    11  2018     45.83       4.98   \n",
      "\n",
      "      Departement  \n",
      "4157           01  \n",
      "43059          04  \n",
      "24047          02  \n",
      "17303          02  \n",
      "11330          01  \n",
      "...           ...  \n",
      "37600          03  \n",
      "17156          02  \n",
      "11516          01  \n",
      "38576          03  \n",
      "16087          01  \n",
      "\n",
      "[21842 rows x 18 columns]\n",
      "       No_disposition  Valeur_fonciere  Nombre_de_lots  Surface_reelle_bati  \\\n",
      "4157                1        295800.00               0                  NaN   \n",
      "43059               1          3000.00               0                  NaN   \n",
      "24047               1        257343.00               0                  NaN   \n",
      "17303               1        100000.00               0                  NaN   \n",
      "11330               1          5000.00               0                  NaN   \n",
      "...               ...              ...             ...                  ...   \n",
      "37600               2         13950.00               0                  NaN   \n",
      "17156               1         92000.00               0                  NaN   \n",
      "11516               1         12095.00               0                  NaN   \n",
      "38576               1           100.00               0                  NaN   \n",
      "16087               1        235000.00               0                  NaN   \n",
      "\n",
      "       Nombre_pieces_principales  Surface_terrain  \n",
      "4157                         NaN           919.00  \n",
      "43059                        NaN          2610.00  \n",
      "24047                        NaN           743.00  \n",
      "17303                        NaN           508.00  \n",
      "11330                        NaN          4900.00  \n",
      "...                          ...              ...  \n",
      "37600                        NaN         12183.00  \n",
      "17156                        NaN           136.00  \n",
      "11516                        NaN            30.00  \n",
      "38576                        NaN           620.00  \n",
      "16087                        NaN          1123.00  \n",
      "\n",
      "[21842 rows x 6 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nDecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/nathan/fac/m2/s1/python/projet_prediction/src/data_preprocessing.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/fac/m2/s1/python/projet_prediction/src/data_preprocessing.ipynb#X31sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m y \u001b[39m=\u001b[39m individus_manquants[\u001b[39m'\u001b[39m\u001b[39mCode_type_local\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/fac/m2/s1/python/projet_prediction/src/data_preprocessing.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Prédisez Code_type_local pour les individus manquants\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nathan/fac/m2/s1/python/projet_prediction/src/data_preprocessing.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m predictions_code_type_local \u001b[39m=\u001b[39m modele_decision_tree\u001b[39m.\u001b[39;49mpredict(X_manquants)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/fac/m2/s1/python/projet_prediction/src/data_preprocessing.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Remplacez les valeurs manquantes dans le DataFrame original avec les prédictions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nathan/fac/m2/s1/python/projet_prediction/src/data_preprocessing.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m df_sauvegarde_with_nan\u001b[39m.\u001b[39mloc[df_sauvegarde_with_nan[\u001b[39m'\u001b[39m\u001b[39mCode_type_local\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misna(), \u001b[39m'\u001b[39m\u001b[39mCode_type_local\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m predictions_code_type_local\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:505\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \n\u001b[1;32m    484\u001b[0m \u001b[39mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    504\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 505\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input)\n\u001b[1;32m    506\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m    507\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:471\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[0;32m--> 471\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    472\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    473\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc\n\u001b[1;32m    474\u001b[0m     ):\n\u001b[1;32m    475\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nDecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Réimporter les données de base, tous ceux qui ont Code_type_local == NaN\n",
    "# puis appliquer le modèle le classif => sauvegarder pleins d'individus\n",
    "\n",
    "# Réimportez les données de base avec Code_type_local manquant\n",
    "\n",
    "#Index(['Nombre_pieces_principales', 'Surface_terrain']\n",
    "\n",
    "# Sélectionnez les individus avec Code_type_local manquant\n",
    "individus_manquants = df_sauvegarde_with_nan[df_sauvegarde_with_nan['Code_type_local'].isna()]\n",
    "print(individus_manquants)\n",
    "X_manquants = individus_manquants.drop(columns=['Code_type_local','Commune','Section','No_plan','Nature_culture','Departement','Code_postal','day','month','year','latitude','longitude'])\n",
    "print(X_manquants)\n",
    "y = individus_manquants['Code_type_local']\n",
    "\n",
    "\n",
    "# Prédisez Code_type_local pour les individus manquants\n",
    "predictions_code_type_local = modele_decision_tree.predict(X_manquants)\n",
    "\n",
    "# Remplacez les valeurs manquantes dans le DataFrame original avec les prédictions\n",
    "df_sauvegarde_with_nan.loc[df_sauvegarde_with_nan['Code_type_local'].isna(), 'Code_type_local'] = predictions_code_type_local\n",
    "\n",
    "\n",
    "df_sauvegarde_with_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last = pd.concat([df,df_sauvegarde_with_nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No_disposition              0.00\n",
      "Valeur_fonciere             0.00\n",
      "Code_postal                 0.00\n",
      "Commune                     0.00\n",
      "Section                     0.00\n",
      "No_plan                     0.00\n",
      "Nombre_de_lots              0.00\n",
      "Code_type_local             0.00\n",
      "Surface_reelle_bati         0.00\n",
      "Nombre_pieces_principales   0.00\n",
      "day                         0.00\n",
      "month                       0.00\n",
      "year                        0.00\n",
      "latitude                    0.00\n",
      "longitude                   0.00\n",
      "Departement                 0.00\n",
      "dtype: float64\n",
      "8379674\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_disposition</th>\n",
       "      <th>Valeur_fonciere</th>\n",
       "      <th>Code_postal</th>\n",
       "      <th>Commune</th>\n",
       "      <th>Section</th>\n",
       "      <th>No_plan</th>\n",
       "      <th>Nombre_de_lots</th>\n",
       "      <th>Code_type_local</th>\n",
       "      <th>Surface_reelle_bati</th>\n",
       "      <th>Nombre_pieces_principales</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Departement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>668039</th>\n",
       "      <td>1</td>\n",
       "      <td>109500.00</td>\n",
       "      <td>43130</td>\n",
       "      <td>RETOURNAC</td>\n",
       "      <td>B</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>77.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>45.22</td>\n",
       "      <td>4.03</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352633</th>\n",
       "      <td>1</td>\n",
       "      <td>305000.00</td>\n",
       "      <td>27600</td>\n",
       "      <td>FONTAINE BELLENGER</td>\n",
       "      <td>A</td>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>170.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>49.18</td>\n",
       "      <td>1.25</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518138</th>\n",
       "      <td>1</td>\n",
       "      <td>91000.00</td>\n",
       "      <td>34390</td>\n",
       "      <td>SAINT JULIEN</td>\n",
       "      <td>B</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>43.58</td>\n",
       "      <td>2.90</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405590</th>\n",
       "      <td>1</td>\n",
       "      <td>194200.00</td>\n",
       "      <td>91150</td>\n",
       "      <td>ETAMPES</td>\n",
       "      <td>AP</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>48.42</td>\n",
       "      <td>2.14</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908755</th>\n",
       "      <td>1</td>\n",
       "      <td>80000.00</td>\n",
       "      <td>59950</td>\n",
       "      <td>AUBY</td>\n",
       "      <td>B</td>\n",
       "      <td>4881</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>50.41</td>\n",
       "      <td>3.06</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         No_disposition  Valeur_fonciere Code_postal             Commune  \\\n",
       "668039                1        109500.00       43130           RETOURNAC   \n",
       "352633                1        305000.00       27600  FONTAINE BELLENGER   \n",
       "518138                1         91000.00       34390        SAINT JULIEN   \n",
       "1405590               1        194200.00       91150             ETAMPES   \n",
       "908755                1         80000.00       59950                AUBY   \n",
       "\n",
       "        Section  No_plan  Nombre_de_lots  Code_type_local  \\\n",
       "668039        B      163               0             1.00   \n",
       "352633        A      884               0             1.00   \n",
       "518138        B      253               0             1.00   \n",
       "1405590      AP      181               0             1.00   \n",
       "908755        B     4881               0             1.00   \n",
       "\n",
       "         Surface_reelle_bati  Nombre_pieces_principales day month  year  \\\n",
       "668039                 77.00                       3.00  19     7  2018   \n",
       "352633                170.00                       5.00  18     8  2018   \n",
       "518138                 80.00                       3.00   5     2  2018   \n",
       "1405590               110.00                       5.00  21     6  2018   \n",
       "908755                 76.00                       3.00  14     9  2018   \n",
       "\n",
       "         latitude  longitude Departement  \n",
       "668039      45.22       4.03          43  \n",
       "352633      49.18       1.25          27  \n",
       "518138      43.58       2.90          34  \n",
       "1405590     48.42       2.14          91  \n",
       "908755      50.41       3.06          59  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_surface_by_type = df_last.groupby('Code_type_local')['Surface_reelle_bati'].median()\n",
    "# Remplacez les NaN dans \"Surface_reelle_bat\" par la médiane correspondante basée sur \"Code_type_local\"\n",
    "df_last['Surface_reelle_bati'] = df_last['Surface_reelle_bati'].fillna(df_last['Code_type_local'].map(median_surface_by_type))\n",
    "\n",
    "median_surface_by_type = df_last.groupby('Code_type_local')['Nombre_pieces_principales'].median()\n",
    "# Remplacez les NaN dans \"Surface_reelle_bat\" par la médiane correspondante basée sur \"Code_type_local\"\n",
    "df_last['Nombre_pieces_principales'] = df_last['Nombre_pieces_principales'].fillna(df_last['Code_type_local'].map(median_surface_by_type))\n",
    "\n",
    "\n",
    "df_last = df_last.drop(columns=[\"Nature_culture\",\"Surface_terrain\"])\n",
    "\n",
    "pourcentages_nan = (df_last.isna().sum() / len(df_last)) * 100\n",
    "# Affichez les pourcentages de NaN pour chaque colonne\n",
    "print(pourcentages_nan)\n",
    "print(len(df_last))\n",
    "\n",
    "df_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_disposition</th>\n",
       "      <th>Valeur_fonciere</th>\n",
       "      <th>Code_postal</th>\n",
       "      <th>Commune</th>\n",
       "      <th>Section</th>\n",
       "      <th>No_plan</th>\n",
       "      <th>Nombre_de_lots</th>\n",
       "      <th>Code_type_local</th>\n",
       "      <th>Surface_reelle_bati</th>\n",
       "      <th>Nombre_pieces_principales</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Departement</th>\n",
       "      <th>Prix_moyen_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>668039</th>\n",
       "      <td>1</td>\n",
       "      <td>109500.00</td>\n",
       "      <td>43130</td>\n",
       "      <td>RETOURNAC</td>\n",
       "      <td>B</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>77.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>45.22</td>\n",
       "      <td>4.03</td>\n",
       "      <td>43</td>\n",
       "      <td>943.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352633</th>\n",
       "      <td>1</td>\n",
       "      <td>305000.00</td>\n",
       "      <td>27600</td>\n",
       "      <td>FONTAINE BELLENGER</td>\n",
       "      <td>A</td>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>170.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>49.18</td>\n",
       "      <td>1.25</td>\n",
       "      <td>27</td>\n",
       "      <td>1389.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518138</th>\n",
       "      <td>1</td>\n",
       "      <td>91000.00</td>\n",
       "      <td>34390</td>\n",
       "      <td>SAINT JULIEN</td>\n",
       "      <td>B</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>43.58</td>\n",
       "      <td>2.90</td>\n",
       "      <td>34</td>\n",
       "      <td>1773.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405590</th>\n",
       "      <td>1</td>\n",
       "      <td>194200.00</td>\n",
       "      <td>91150</td>\n",
       "      <td>ETAMPES</td>\n",
       "      <td>AP</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>48.42</td>\n",
       "      <td>2.14</td>\n",
       "      <td>91</td>\n",
       "      <td>2298.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908755</th>\n",
       "      <td>1</td>\n",
       "      <td>80000.00</td>\n",
       "      <td>59950</td>\n",
       "      <td>AUBY</td>\n",
       "      <td>B</td>\n",
       "      <td>4881</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>50.41</td>\n",
       "      <td>3.06</td>\n",
       "      <td>59</td>\n",
       "      <td>1381.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         No_disposition  Valeur_fonciere  Code_postal             Commune  \\\n",
       "668039                1        109500.00        43130           RETOURNAC   \n",
       "352633                1        305000.00        27600  FONTAINE BELLENGER   \n",
       "518138                1         91000.00        34390        SAINT JULIEN   \n",
       "1405590               1        194200.00        91150             ETAMPES   \n",
       "908755                1         80000.00        59950                AUBY   \n",
       "\n",
       "        Section  No_plan  Nombre_de_lots  Code_type_local  \\\n",
       "668039        B      163               0             1.00   \n",
       "352633        A      884               0             1.00   \n",
       "518138        B      253               0             1.00   \n",
       "1405590      AP      181               0             1.00   \n",
       "908755        B     4881               0             1.00   \n",
       "\n",
       "         Surface_reelle_bati  Nombre_pieces_principales  day  month  year  \\\n",
       "668039                 77.00                       3.00   19      7  2018   \n",
       "352633                170.00                       5.00   18      8  2018   \n",
       "518138                 80.00                       3.00    5      2  2018   \n",
       "1405590               110.00                       5.00   21      6  2018   \n",
       "908755                 76.00                       3.00   14      9  2018   \n",
       "\n",
       "         latitude  longitude Departement  Prix_moyen_m2  \n",
       "668039      45.22       4.03          43         943.19  \n",
       "352633      49.18       1.25          27        1389.41  \n",
       "518138      43.58       2.90          34        1773.86  \n",
       "1405590     48.42       2.14          91        2298.42  \n",
       "908755      50.41       3.06          59        1381.45  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajouter variable Prix_moyen_m2\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# Groupez les données par 'Commune' et calculez la somme de 'Surface_reel' et 'Valeur_fonciere' pour chaque commune\n",
    "groupe_commune = df.groupby('Commune').agg({'Surface_reelle_bati': 'sum', 'Valeur_fonciere': 'sum'})\n",
    "\n",
    "# Calculez le prix moyen au mètre carré par commune\n",
    "groupe_commune['Prix_moyen_m2'] = groupe_commune['Valeur_fonciere'] / groupe_commune['Surface_reelle_bati']\n",
    "\n",
    "\n",
    "# Fusionnez le DataFrame original avec le DataFrame groupe_commune sur la colonne 'Commune'\n",
    "df = pd.merge(df, groupe_commune[['Prix_moyen_m2']], left_on='Commune', right_index=True, how='left')\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)  # Remplace les inf par NaN\n",
    "df = df.dropna(subset=['Prix_moyen_m2'], how='any')  # Supprime les lignes avec NaN dans 'Prix_moyen_m2'\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_vers_projet = '/home/nathan/fac/m2/s1/python/projet_prediction/'\n",
    "\n",
    "# Définir l'espace de travail (répertoire de travail)\n",
    "#os.chdir(chemin_vers_projet)\n",
    "\n",
    "df.to_pickle('../data/dataframe_clean_last_version.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre individus dataframe global :  5784134 \n",
      "\n",
      "Index(['Nombre_de_lots', 'Surface_reelle_bati', 'Nombre_pieces_principales',\n",
      "       'year', 'Departement', 'Prix_moyen_m2'],\n",
      "      dtype='object')\n",
      "Erreur Quadratique Moyenne (MSE) :  8182930287.198272\n",
      "         Valeur_reelle  Valeur_predite\n",
      "1371275      311050.00       206969.66\n",
      "579627       405000.00       243085.48\n",
      "1311081      137500.00       160495.53\n",
      "1299476      420000.00       354781.80\n",
      "746510       200000.00       155329.95\n",
      "...                ...             ...\n",
      "503555       225000.00       187819.71\n",
      "134534        30000.00       108996.47\n",
      "941002       203000.00       196204.70\n",
      "680057        47491.00       114911.40\n",
      "381015       133000.00       120437.30\n",
      "\n",
      "[2892067 rows x 2 columns]\n",
      "R carré : 0.4294134400437032\n"
     ]
    }
   ],
   "source": [
    "# TEST MAISON #\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# MSE : 3 184 771 589 078.1714 avec 5 colonnes et 100 000 lignes au début du programme (régression linéaire)\n",
    "# MSE : 9 351 187 946 604.617 avec 11 colonnes et 700 000 lignes au début du programme\n",
    "# MSE : 9 621 056 123 391.139 en changeant le code type local == 1\n",
    "# MSE : 2 642 213 419 979.8486 avec 5 colonnes et 100 000 lignes au début du programme (avec year, code postal, et nature mutation) (code local == 1)\n",
    "# MSE : 2 642 223 129 457.908 avec pareil mais Lasso (few features should be important) (code local == 1)\n",
    "# MSE : 2 283 126 024 532.157 avec pareil mais Ridge (lot of features should be important) (code local == 1)\n",
    "# MSE : 1 481 548 894 581.531 avec Ridge mais 300 000 lignes (code local == 1)\n",
    "# MSE : 1 419 765 756 499.442 avec Lasso mais 300 000 lignes (code local == 1)\n",
    "# MSE : 15 011 506 135 748.002 avec Lasso mais 1 021 105 lignes (code local == 1)\n",
    "# MSE : 6 011 506 135 748.002 avec Ridge mais ... lignes (code local == 1)\n",
    "\n",
    "df_test = df.copy()\n",
    "# test seulement avec le code local == 1\n",
    "df_test = df_test[df_test['Code_type_local'] == 1]\n",
    "df_test = df_test.drop(columns=[\"Code_type_local\"])\n",
    "\n",
    "\n",
    "print(\"nombre individus dataframe global : \",len(df_test), \"\\n\")\n",
    "\n",
    "\n",
    "# test drop colonne\n",
    "X = df_test.drop(columns=['Valeur_fonciere', 'Commune', 'Section','day','No_plan', 'No_disposition','latitude','longitude','Code_postal','month'])\n",
    "print(X.columns)\n",
    "\n",
    "X = pd.get_dummies(X, columns=['year','Departement'])\n",
    "\n",
    "\n",
    "y = df_test['Valeur_fonciere']  # Variable cible\n",
    "\n",
    "# Séparez les données en ensembles d'entraînement et de test (par exemple, 80% pour l'entraînement et 20% pour le test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialisez le modèle Ridge\n",
    "modele_ridge = Ridge(alpha=1.0)  # L'alpha est le paramètre de régularisation\n",
    "\n",
    "modele_ridge.fit(X_train,y_train)\n",
    "# Entraînez le modèle sur les donné\n",
    "# Prédisez les valeurs sur l'ensemble de test\n",
    "predictions = modele_ridge.predict(X_test)\n",
    "\n",
    "# Calculez l'erreur quadratique moyenne (MSE) pour évaluer la performance du modèle\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "# Affichez l'erreur quadratique moyenne\n",
    "print(\"Erreur Quadratique Moyenne (MSE) : \", mse)\n",
    "\n",
    "# Créez un DataFrame avec les valeurs prédites et les valeurs réelles\n",
    "resultats = pd.DataFrame(\n",
    "    {'Valeur_reelle': y_test, 'Valeur_predite': predictions})\n",
    "\n",
    "# Affichez les valeurs prédites par rapport aux valeurs réelles\n",
    "print(resultats)\n",
    "# Calculez le R carré\n",
    "r2 = r2_score(y_test, predictions)\n",
    "# Affichez le R carré\n",
    "print(\"R carré :\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code_type_local\n",
      "1.00    5784134\n",
      "2.00    1187345\n",
      "3.00    1116612\n",
      "4.00     291577\n",
      "Name: count, dtype: int64\n",
      "nombre individus dataframe global :  1187345 \n",
      "\n",
      "Index(['Nombre_de_lots', 'Surface_reelle_bati', 'Nombre_pieces_principales',\n",
      "       'year', 'Departement', 'Prix_moyen_m2'],\n",
      "      dtype='object')\n",
      "Erreur Quadratique Moyenne (MSE) :  6592433068.862309\n",
      "         Valeur_reelle  Valeur_predite\n",
      "1434216      260000.00       231422.73\n",
      "1092898       19520.00        -2607.74\n",
      "231834        71000.00       133996.88\n",
      "633829        76600.00       120807.99\n",
      "1118660      123000.00       206179.80\n",
      "...                ...             ...\n",
      "1118698       94700.00       122015.56\n",
      "1577661      159200.00       180227.92\n",
      "1365512       92000.00       143116.70\n",
      "1398977      188000.00       229692.37\n",
      "1300946      219000.00       162092.57\n",
      "\n",
      "[237469 rows x 2 columns]\n",
      "R carré : 0.4473017101818916\n"
     ]
    }
   ],
   "source": [
    "# TEST APPARTEMENT #\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "df_test = df.copy()\n",
    "\n",
    "# test seulement avec le code local == 2\n",
    "df_test = df_test[df_test['Code_type_local'] == 2]\n",
    "print(df['Code_type_local'].value_counts())\n",
    "\n",
    "df_test = df_test.drop(columns=[\"Code_type_local\"])\n",
    "\n",
    "print(\"nombre individus dataframe global : \",len(df_test), \"\\n\")\n",
    "\n",
    "\n",
    "# test drop colonne\n",
    "X = df_test.drop(columns=['Valeur_fonciere', 'Commune', 'Section','day','No_plan', 'No_disposition','latitude','longitude','Code_postal','month'])\n",
    "print(X.columns)\n",
    "\n",
    "X = pd.get_dummies(X, columns=['year','Departement'])\n",
    "\n",
    "y = df_test['Valeur_fonciere']  # Variable cible\n",
    "\n",
    "# Séparez les données en ensembles d'entraînement et de test (par exemple, 80% pour l'entraînement et 20% pour le test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialisez le modèle Ridge\n",
    "modele_ridge = Ridge(alpha=1.0)  # L'alpha est le paramètre de régularisation\n",
    "\n",
    "modele_ridge.fit(X_train,y_train)\n",
    "\n",
    "# Entraînez le modèle sur les donné\n",
    "# Prédisez les valeurs sur l'ensemble de test\n",
    "predictions = modele_ridge.predict(X_test)\n",
    "\n",
    "# Calculez l'erreur quadratique moyenne (MSE) pour évaluer la performance du modèle\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "# Affichez l'erreur quadratique moyenne\n",
    "print(\"Erreur Quadratique Moyenne (MSE) : \", mse)\n",
    "\n",
    "# Créez un DataFrame avec les valeurs prédites et les valeurs réelles\n",
    "resultats = pd.DataFrame(\n",
    "    {'Valeur_reelle': y_test, 'Valeur_predite': predictions})\n",
    "\n",
    "# Affichez les valeurs prédites par rapport aux valeurs réelles\n",
    "print(resultats)\n",
    "# Calculez le R carré\n",
    "r2 = r2_score(y_test, predictions)\n",
    "# Affichez le R carré\n",
    "print(\"R carré :\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code_type_local\n",
      "1.00    5784134\n",
      "2.00    1187345\n",
      "3.00    1116612\n",
      "4.00     291577\n",
      "Name: count, dtype: int64\n",
      "nombre individus dataframe global :  1116612 \n",
      "\n",
      "Index(['Nombre_de_lots', 'Surface_reelle_bati', 'Nombre_pieces_principales',\n",
      "       'year', 'Departement', 'Prix_moyen_m2'],\n",
      "      dtype='object')\n",
      "Erreur Quadratique Moyenne (MSE) :  12131310425.678213\n",
      "         Valeur_reelle  Valeur_predite\n",
      "1433992      152000.00       156556.30\n",
      "30487         60800.00       123911.69\n",
      "792353        35000.00       114505.42\n",
      "1806541      190000.00       194401.83\n",
      "1525588      202000.00       171371.80\n",
      "...                ...             ...\n",
      "1382357       28550.00       180417.47\n",
      "901538       228000.00       184398.12\n",
      "350622       249500.00       134338.01\n",
      "376118        80000.00        80562.82\n",
      "848621       168100.00       142789.13\n",
      "\n",
      "[223323 rows x 2 columns]\n",
      "R carré : 0.16893921402358458\n"
     ]
    }
   ],
   "source": [
    "# TEST dépendance #\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "df_test = df.copy()\n",
    "\n",
    "# test seulement avec le code local == 3\n",
    "df_test = df_test[df_test['Code_type_local'] == 3]\n",
    "print(df['Code_type_local'].value_counts())\n",
    "\n",
    "df_test = df_test.drop(columns=[\"Code_type_local\"])\n",
    "\n",
    "print(\"nombre individus dataframe global : \",len(df_test), \"\\n\")\n",
    "\n",
    "\n",
    "# test drop colonne\n",
    "X = df_test.drop(columns=['Valeur_fonciere', 'Commune', 'Section','day','No_plan', 'No_disposition','latitude','longitude','Code_postal','month'])\n",
    "print(X.columns)\n",
    "\n",
    "X = pd.get_dummies(X, columns=['year','Departement'])\n",
    "\n",
    "y = df_test['Valeur_fonciere']  # Variable cible\n",
    "\n",
    "# Séparez les données en ensembles d'entraînement et de test (par exemple, 80% pour l'entraînement et 20% pour le test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialisez le modèle Ridge\n",
    "modele_ridge = Ridge(alpha=1.0)  # L'alpha est le paramètre de régularisation\n",
    "\n",
    "modele_ridge.fit(X_train,y_train)\n",
    "\n",
    "# Entraînez le modèle sur les donné\n",
    "# Prédisez les valeurs sur l'ensemble de test\n",
    "predictions = modele_ridge.predict(X_test)\n",
    "\n",
    "# Calculez l'erreur quadratique moyenne (MSE) pour évaluer la performance du modèle\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "# Affichez l'erreur quadratique moyenne\n",
    "print(\"Erreur Quadratique Moyenne (MSE) : \", mse)\n",
    "\n",
    "# Créez un DataFrame avec les valeurs prédites et les valeurs réelles\n",
    "resultats = pd.DataFrame(\n",
    "    {'Valeur_reelle': y_test, 'Valeur_predite': predictions})\n",
    "\n",
    "# Affichez les valeurs prédites par rapport aux valeurs réelles\n",
    "print(resultats)\n",
    "# Calculez le R carré\n",
    "r2 = r2_score(y_test, predictions)\n",
    "# Affichez le R carré\n",
    "print(\"R carré :\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre individus dataframe global :  291577 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Nature_culture'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnombre individus dataframe global : \u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mlen\u001b[39m(df_test), \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[39m# test drop colonne\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m X \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mValeur_fonciere\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCommune\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mSection\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mday\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mNo_plan\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mNo_disposition\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mNature_culture\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mlatitude\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mlongitude\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mCode_postal\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m     25\u001b[0m X \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mget_dummies(X, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmonth\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mDepartement\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Nature_culture'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# # TEST Dépendance #\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# df_test = df.copy()\n",
    "\n",
    "# # test seulement avec le code local == 2\n",
    "# df_test = df_test[df_test['Code_type_local'] == 4]\n",
    "\n",
    "# df_test = df_test.drop(columns=[\"Code_type_local\"])\n",
    "\n",
    "# print(\"nombre individus dataframe global : \",len(df_test), \"\\n\")\n",
    "\n",
    "\n",
    "# # test drop colonne\n",
    "# X = df_test.drop(columns=['Valeur_fonciere', 'Commune', 'Section','day','No_plan', 'No_disposition', 'Nature_culture','latitude','longitude','Code_postal'])\n",
    "# print(X.columns)\n",
    "\n",
    "# X = pd.get_dummies(X, columns=['month','year','Departement'])\n",
    "\n",
    "\n",
    "# y = df_test['Valeur_fonciere']  # Variable cible\n",
    "\n",
    "# # Séparez les données en ensembles d'entraînement et de test (par exemple, 80% pour l'entraînement et 20% pour le test)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialisez le modèle Ridge\n",
    "# modele_ridge = Ridge(alpha=1.0)  # L'alpha est le paramètre de régularisation\n",
    "\n",
    "# modele_ridge.fit(X_train,y_train)\n",
    "\n",
    "# # Entraînez le modèle sur les donné\n",
    "# # Prédisez les valeurs sur l'ensemble de test\n",
    "# predictions = modele_ridge.predict(X_test)\n",
    "\n",
    "# # Calculez l'erreur quadratique moyenne (MSE) pour évaluer la performance du modèle\n",
    "# mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "# # Affichez l'erreur quadratique moyenne\n",
    "# print(\"Erreur Quadratique Moyenne (MSE) : \", mse)\n",
    "\n",
    "# # Créez un DataFrame avec les valeurs prédites et les valeurs réelles\n",
    "# resultats = pd.DataFrame(\n",
    "#     {'Valeur_reelle': y_test, 'Valeur_predite': predictions})\n",
    "\n",
    "# # Affichez les valeurs prédites par rapport aux valeurs réelles\n",
    "# print(resultats)\n",
    "# # Calculez le R carré\n",
    "# r2 = r2_score(y_test, predictions)\n",
    "# # Affichez le R carré\n",
    "# print(\"R carré :\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : \n",
    "# enlever les extrêmes (1e symbolique etc...)\n",
    "# imputation de données manquantes => KNN,  arbre !\n",
    "# puis clustering sur le type de local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.16.tar.gz (83 kB)\n",
      "     ---------------------------------------- 0.0/83.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 83.6/83.6 kB 2.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\nagrimault\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\python311\\lib\\site-packages (from kaggle) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\nagrimault\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from kaggle) (4.66.1)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\python311\\lib\\site-packages (from kaggle) (2.0.6)\n",
      "Collecting bleach (from kaggle)\n",
      "  Obtaining dependency information for bleach from https://files.pythonhosted.org/packages/ea/63/da7237f805089ecc28a3f36bca6a21c31fcbc2eb380f3b8f1be3312abd14/bleach-6.1.0-py3-none-any.whl.metadata\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: webencodings in c:\\python311\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 0.0/78.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 78.2/78.2 kB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->kaggle) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\nagrimault\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.8/162.8 kB 4.9 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (pyproject.toml): started\n",
      "  Building wheel for kaggle (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110693 sha256=a8328370aa32accb6ba09d0d031ba8339c5b0cedcaa4075222813b2205079b61\n",
      "  Stored in directory: c:\\users\\nagrimault\\appdata\\local\\pip\\cache\\wheels\\6a\\2b\\d0\\457dd27de499e9423caf738e743c4a3f82886ee6b19f89d5b7\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, bleach, kaggle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Python311\\Lib\\site-packages)\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] Le fichier spécifié est introuvable: 'C:\\\\Python311\\\\Scripts\\\\slugify.exe' -> 'C:\\\\Python311\\\\Scripts\\\\slugify.exe.deleteme'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
